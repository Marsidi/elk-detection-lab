---
redirect_from:
  - "/import-mordor"
title: |-
  Consume Mordor Datasets
pagenum: 6
prev_page:
  url: /export_mordor.html
next_page:
  url: /notebooks/small/windows/windows.html
suffix: .md
search: helk kafkacat installation info kafka com docker data github mordor build basic elk kibana src repo using send file install cybrwardg bash consume img images png producer broker edenhill compose following version git set download json start logs installed elastic ubuntu run cd hunting jupyter ip installing via empiredcsync dcsync c d available real pipeline style tool mode messages stdin being apache system non option www stack ce docs container based running iframe picture instructions sure latest deb package quick memory clone license ksql ngnix elastalert ui password tar b t p l ff cfcdcd notebook datasets catapult main image

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Consume Mordor Datasets</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="images/catapult-main-image.png"></p>
<p>You can simply download the json files available in this repo and start using some grep fu! if you feel like it.
However, there are other more efficient ways you can consume the pre-recorded data and even simulate a real data pipeline to ingest the data to your own SIEM or data lake.</p>
<h2 id="Kafkacat-Style">Kafkacat Style<a class="anchor-link" href="#Kafkacat-Style"> </a></h2><p>You can start using a tool named Kafkacat to act as a Kafka producer and send data to Kafka brokers.
In producer mode, Kafkacat reads messages from standard input (stdin) or a file.
This means that you can send data back to any other Kafka broker that you are using as part of your pipeline.
You can just grab the logs from this repo and re-play them as if they were being ingested in real-time.</p>
<h3 id="Requirements">Requirements<a class="anchor-link" href="#Requirements"> </a></h3><ul>
<li><a href="http://kafka.apache.org/">Kafka Broker</a> : A distributed publish-subscribe messaging system that is designed to be fast, scalable, fault-tolerant, and durable  (<strong>Installed by HELK</strong>).</li>
<li><a href="https://github.com/edenhill/kafkacat">Kafkacat</a> : A generic non-JVM producer and consumer for Apache Kafka &gt;=0.8, think of it as a netcat for Kafka.</li>
<li><a href="https://www.elastic.co/elk-stack">HELK (Basic Option)</a>: An elastic ELK (Elasticsearch, Logstash, Kibana) stack.</li>
<li><a href="https://docs.docker.com/install/">Docker CE</a> : Docker Community Edition (CE) is ideal for developers and small teams looking to get started with Docker and experimenting with container-based apps (<strong>Installed by HELK</strong>).</li>
<li><a href="https://docs.docker.com/compose/">Docker Compose</a> : a tool for defining and running multi-container Docker applications (<strong>Installed by HELK</strong>).</li>
</ul>
<p><img src="images/kafka-kafkacat.png"></p>
<h3 id="Consume-Logs">Consume Logs<a class="anchor-link" href="#Consume-Logs"> </a></h3><iframe width="560" height="315" src="https://www.youtube.com/embed/ADGWxofSf4o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>Install Kafkacat following the <a href="https://github.com/edenhill/kafkacat#install">instructions from the official Kafkacat repo</a></p>
<ul>
<li>If you are using a debian-based system, make sure you install the latest Kafkacat deb package.</li>
<li>I recommend at least Ubuntu 18.04. You can check its <a href="https://packages.ubuntu.com/bionic/kafkacat">Kafkacat deb package version</a> and compare it with the latest one in the <a href="https://github.com/edenhill/kafkacat/releases">Kafkacat GitHub repo</a>.</li>
<li>You can also install it from source following the <a href="https://github.com/edenhill/kafkacat#quick-build">Quick Build</a> instructions.</li>
</ul>
<p>Download and run the <a href="https://github.com/Cyb3rWard0g/HELK">HELK</a>. Make sure you have enough memory to run the basic build.
You can run it with 5-6GB of RAM now (More information <a href="https://github.com/Cyb3rWard0g/HELK/wiki/Installation">here</a>).</p>
<div class="highlight"><pre><span></span>$ git clone https://github.com/Cyb3rWard0g/HELK.git
$ <span class="nb">cd</span> HELK/docker
$ sudo ./helk_install
</pre></div>
<p>Use the defaults (Option 1 and Basic license)</p>

<pre><code>**********************************************
**          HELK - THE HUNTING ELK          **
**                                          **
** Author: Roberto Rodriguez (@Cyb3rWard0g) **
** HELK build version: v0.1.7-alpha02262019 **
** HELK ELK version: 6.6.1                  **
** License: GPL-3.0                         **
**********************************************

[HELK-INSTALLATION-INFO] HELK being hosted on a Linux box
[HELK-INSTALLATION-INFO] Available Memory: 12541 MBs
[HELK-INSTALLATION-INFO] You're using ubuntu version xenial

*****************************************************
*      HELK - Docker Compose Build Choices          *
*****************************************************

1. KAFKA + KSQL + ELK + NGNIX + ELASTALERT
2. KAFKA + KSQL + ELK + NGNIX + ELASTALERT + SPARK + JUPYTER

Enter build choice [ 1 - 2]: 1
[HELK-INSTALLATION-INFO] HELK build set to 1
[HELK-INSTALLATION-INFO] Set HELK elastic subscription (basic or trial): basic
[HELK-INSTALLATION-INFO] Set HELK IP. Default value is your current IP: 192.168.64.138
[HELK-INSTALLATION-INFO] Set HELK Kibana UI Password: hunting
[HELK-INSTALLATION-INFO] Verify HELK Kibana UI Password: hunting
[HELK-INSTALLATION-INFO] Installing htpasswd..
[HELK-INSTALLATION-INFO] Installing docker via convenience script..
[HELK-INSTALLATION-INFO] Installing docker-compose..
[HELK-INSTALLATION-INFO] Checking local vm.max_map_count variable and setting it to 4120294
[HELK-INSTALLATION-INFO] Building &amp; running HELK from helk-kibana-analysis-basic.yml file..</code></pre>
<p>Download the mordor repo and choose your technique:</p>
<div class="highlight"><pre><span></span>$ <span class="nb">cd</span> ../../
$ git clone https://github.com/Cyb3rWard0g/mordor.git
$ <span class="nb">cd</span> mordor/small_datasets/windows/credential_access/credential_dumping_T1003/credentials_from_ad/
</pre></div>
<p>Decompress the specific mordor log file</p>
<div class="highlight"><pre><span></span>$ tar -xzvf empire_dcsync.tar.gz
x empire_dcsync_2019-03-01174830.json
</pre></div>
<p>Send the data to HELK via Kafcakat with the following flags:</p>
<ul>
<li><strong>-b</strong>: Kafka Broker</li>
<li><strong>-t</strong>: Topic in the Kafka Broker to send the data to</li>
<li><strong>-P</strong>: Producer mode</li>
<li><strong>-l</strong>: Send messages from a file separated by delimiter, as with stdin. (only one file allowed)</li>
</ul>
<div class="highlight"><pre><span></span>$ kafkacat -b &lt;HELK IP&gt;:9092 -t winlogbeat -P -l empire_dcsync_2019-03-01174830.json
</pre></div>
<p>Browse to your Kibana Discover view and start going through the data</p>
<p><img src="images/mordor-dcsync-logs.png"></p>
<p>You could look for potential DCSync actvity from a non-Domain-Controller account with the following query in Kibana:</p>
<div class="highlight"><pre><span></span>event_id:4662 NOT user_name:*$ AND object_properties:<span class="o">(</span><span class="s2">&quot;*1131f6aa-9c07-11d1-f79f-00c04fc2dcd2*&quot;</span> OR <span class="s2">&quot;*1131f6ad-9c07-11d1-f79f-00c04fc2dcd2*&quot;</span> OR <span class="s2">&quot;*89e95b76-444d-4c62-991a-0facbeda640c*&quot;</span><span class="o">)</span>
</pre></div>
<p><img src="images/mordor-dcsync-found.png"></p>
<h2 id="Jupyter-Notebook-Style">Jupyter Notebook Style<a class="anchor-link" href="#Jupyter-Notebook-Style"> </a></h2><p>You can consume mordor data directly with a Jupyter notebook and analyze it via python libraries such as Pandas or PySpark.</p>

</div>
</div>
</div>
</div>

 


    </main>
    